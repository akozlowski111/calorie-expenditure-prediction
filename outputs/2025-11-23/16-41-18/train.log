[2025-11-23 16:41:18,799][__main__][INFO] - Ustawiono seed: 42
[2025-11-23 16:41:18,799][__main__][INFO] - Rozpoczynam trening z konfiguracją: {'training': {'seed': 42, 'val_fraction': 0.1, 'tuning_epochs': 10, 'final_epochs': 100, 'patience': 10}, 'search_space': {'architectures': [[7, 16, 8, 1], [7, 32, 16, 1], [7, 64, 32, 1]], 'learning_rates': [0.001, 0.01, 0.0001], 'batch_sizes': [32, 64, 128], 'momentums': [0.5, 0.9, 0.95], 'dropout_rates': [0.0, 0.1, 0.2, 0.3]}, 'data': {'train': 'data/train.csv', 'test': 'data/test.csv'}, 'inference': {'batch_size': 256, 'model_path': '', 'stats_path': '', 'submission_path': 'outputs/submission.csv'}}
[2025-11-23 16:41:18,799][__main__][INFO] - Wykryte urządzenie: cpu
[2025-11-23 16:41:19,612][__main__][INFO] - Próbki treningowe: 675000 | walidacyjne: 75000
[2025-11-23 16:41:19,612][__main__][INFO] - Uruchamiam grid search (81 kombinacji)...
[2025-11-23 16:42:16,773][__main__][INFO] - [1/81] arch=7->16->8->1 lr=0.001 batch=32 mom=0.50 -> val_rmsle=0.0785
[2025-11-23 16:43:13,676][__main__][INFO] - [2/81] arch=7->16->8->1 lr=0.001 batch=32 mom=0.90 -> val_rmsle=0.0636
[2025-11-23 16:44:10,392][__main__][INFO] - [3/81] arch=7->16->8->1 lr=0.001 batch=32 mom=0.95 -> val_rmsle=0.0612
[2025-11-23 16:44:46,248][__main__][INFO] - [4/81] arch=7->16->8->1 lr=0.001 batch=64 mom=0.50 -> val_rmsle=0.0996
[2025-11-23 16:45:21,632][__main__][INFO] - [5/81] arch=7->16->8->1 lr=0.001 batch=64 mom=0.90 -> val_rmsle=0.0669
[2025-11-23 16:45:57,702][__main__][INFO] - [6/81] arch=7->16->8->1 lr=0.001 batch=64 mom=0.95 -> val_rmsle=0.0626
[2025-11-23 16:46:24,432][__main__][INFO] - [7/81] arch=7->16->8->1 lr=0.001 batch=128 mom=0.50 -> val_rmsle=0.1278
[2025-11-23 16:46:52,722][__main__][INFO] - [8/81] arch=7->16->8->1 lr=0.001 batch=128 mom=0.90 -> val_rmsle=0.0779
[2025-11-23 16:47:18,838][__main__][INFO] - [9/81] arch=7->16->8->1 lr=0.001 batch=128 mom=0.95 -> val_rmsle=0.0658
[2025-11-23 16:48:16,713][__main__][INFO] - [10/81] arch=7->16->8->1 lr=0.01 batch=32 mom=0.50 -> val_rmsle=0.0612
[2025-11-23 16:49:16,405][__main__][INFO] - [11/81] arch=7->16->8->1 lr=0.01 batch=32 mom=0.90 -> val_rmsle=0.0601
[2025-11-23 16:50:20,196][__main__][INFO] - [12/81] arch=7->16->8->1 lr=0.01 batch=32 mom=0.95 -> val_rmsle=0.0622
[2025-11-23 16:51:01,687][__main__][INFO] - [13/81] arch=7->16->8->1 lr=0.01 batch=64 mom=0.50 -> val_rmsle=0.0644
[2025-11-23 16:51:43,224][__main__][INFO] - [14/81] arch=7->16->8->1 lr=0.01 batch=64 mom=0.90 -> val_rmsle=0.0612
[2025-11-23 16:52:20,817][__main__][INFO] - [15/81] arch=7->16->8->1 lr=0.01 batch=64 mom=0.95 -> val_rmsle=0.0587
[2025-11-23 16:52:47,788][__main__][INFO] - [16/81] arch=7->16->8->1 lr=0.01 batch=128 mom=0.50 -> val_rmsle=0.0671
[2025-11-23 16:53:14,286][__main__][INFO] - [17/81] arch=7->16->8->1 lr=0.01 batch=128 mom=0.90 -> val_rmsle=0.0622
[2025-11-23 16:53:41,093][__main__][INFO] - [18/81] arch=7->16->8->1 lr=0.01 batch=128 mom=0.95 -> val_rmsle=0.0626
[2025-11-23 16:54:39,305][__main__][INFO] - [19/81] arch=7->16->8->1 lr=0.0001 batch=32 mom=0.50 -> val_rmsle=0.6795
[2025-11-23 16:55:36,933][__main__][INFO] - [20/81] arch=7->16->8->1 lr=0.0001 batch=32 mom=0.90 -> val_rmsle=0.1039
[2025-11-23 16:56:37,741][__main__][INFO] - [21/81] arch=7->16->8->1 lr=0.0001 batch=32 mom=0.95 -> val_rmsle=0.0781
[2025-11-23 16:57:14,346][__main__][INFO] - [22/81] arch=7->16->8->1 lr=0.0001 batch=64 mom=0.50 -> val_rmsle=0.7922
[2025-11-23 16:57:53,730][__main__][INFO] - [23/81] arch=7->16->8->1 lr=0.0001 batch=64 mom=0.90 -> val_rmsle=0.1533
[2025-11-23 16:58:32,161][__main__][INFO] - [24/81] arch=7->16->8->1 lr=0.0001 batch=64 mom=0.95 -> val_rmsle=0.0957
[2025-11-23 16:59:00,950][__main__][INFO] - [25/81] arch=7->16->8->1 lr=0.0001 batch=128 mom=0.50 -> val_rmsle=1.1983
[2025-11-23 16:59:28,769][__main__][INFO] - [26/81] arch=7->16->8->1 lr=0.0001 batch=128 mom=0.90 -> val_rmsle=0.3251
[2025-11-23 17:00:00,687][__main__][INFO] - [27/81] arch=7->16->8->1 lr=0.0001 batch=128 mom=0.95 -> val_rmsle=0.6365
[2025-11-23 17:01:03,911][__main__][INFO] - [28/81] arch=7->32->16->1 lr=0.001 batch=32 mom=0.50 -> val_rmsle=0.0766
[2025-11-23 17:02:05,557][__main__][INFO] - [29/81] arch=7->32->16->1 lr=0.001 batch=32 mom=0.90 -> val_rmsle=0.0600
[2025-11-23 17:03:04,771][__main__][INFO] - [30/81] arch=7->32->16->1 lr=0.001 batch=32 mom=0.95 -> val_rmsle=0.0600
[2025-11-23 17:03:44,514][__main__][INFO] - [31/81] arch=7->32->16->1 lr=0.001 batch=64 mom=0.50 -> val_rmsle=0.0902
[2025-11-23 17:04:20,047][__main__][INFO] - [32/81] arch=7->32->16->1 lr=0.001 batch=64 mom=0.90 -> val_rmsle=0.0645
[2025-11-23 17:04:56,019][__main__][INFO] - [33/81] arch=7->32->16->1 lr=0.001 batch=64 mom=0.95 -> val_rmsle=0.0590
[2025-11-23 17:05:21,165][__main__][INFO] - [34/81] arch=7->32->16->1 lr=0.001 batch=128 mom=0.50 -> val_rmsle=0.1279
[2025-11-23 17:05:46,508][__main__][INFO] - [35/81] arch=7->32->16->1 lr=0.001 batch=128 mom=0.90 -> val_rmsle=0.0714
[2025-11-23 17:06:12,626][__main__][INFO] - [36/81] arch=7->32->16->1 lr=0.001 batch=128 mom=0.95 -> val_rmsle=0.0655
[2025-11-23 17:07:10,045][__main__][INFO] - [37/81] arch=7->32->16->1 lr=0.01 batch=32 mom=0.50 -> val_rmsle=0.0574
[2025-11-23 17:08:07,039][__main__][INFO] - [38/81] arch=7->32->16->1 lr=0.01 batch=32 mom=0.90 -> val_rmsle=0.0587
[2025-11-23 17:09:04,812][__main__][INFO] - [39/81] arch=7->32->16->1 lr=0.01 batch=32 mom=0.95 -> val_rmsle=0.0560
[2025-11-23 17:09:43,337][__main__][INFO] - [40/81] arch=7->32->16->1 lr=0.01 batch=64 mom=0.50 -> val_rmsle=0.0611
[2025-11-23 17:10:18,445][__main__][INFO] - [41/81] arch=7->32->16->1 lr=0.01 batch=64 mom=0.90 -> val_rmsle=0.0575
[2025-11-23 17:10:57,011][__main__][INFO] - [42/81] arch=7->32->16->1 lr=0.01 batch=64 mom=0.95 -> val_rmsle=0.0589
[2025-11-23 17:11:22,384][__main__][INFO] - [43/81] arch=7->32->16->1 lr=0.01 batch=128 mom=0.50 -> val_rmsle=0.0664
[2025-11-23 17:11:47,780][__main__][INFO] - [44/81] arch=7->32->16->1 lr=0.01 batch=128 mom=0.90 -> val_rmsle=0.0642
[2025-11-23 17:12:12,218][__main__][INFO] - [45/81] arch=7->32->16->1 lr=0.01 batch=128 mom=0.95 -> val_rmsle=0.0605
[2025-11-23 17:13:09,782][__main__][INFO] - [46/81] arch=7->32->16->1 lr=0.0001 batch=32 mom=0.50 -> val_rmsle=0.6400
[2025-11-23 17:14:11,470][__main__][INFO] - [47/81] arch=7->32->16->1 lr=0.0001 batch=32 mom=0.90 -> val_rmsle=0.0904
[2025-11-23 17:15:09,997][__main__][INFO] - [48/81] arch=7->32->16->1 lr=0.0001 batch=32 mom=0.95 -> val_rmsle=0.0752
[2025-11-23 17:15:47,989][__main__][INFO] - [49/81] arch=7->32->16->1 lr=0.0001 batch=64 mom=0.50 -> val_rmsle=0.7746
[2025-11-23 17:16:27,457][__main__][INFO] - [50/81] arch=7->32->16->1 lr=0.0001 batch=64 mom=0.90 -> val_rmsle=0.1251
[2025-11-23 17:17:05,422][__main__][INFO] - [51/81] arch=7->32->16->1 lr=0.0001 batch=64 mom=0.95 -> val_rmsle=0.0905
[2025-11-23 17:17:31,011][__main__][INFO] - [52/81] arch=7->32->16->1 lr=0.0001 batch=128 mom=0.50 -> val_rmsle=0.8705
[2025-11-23 17:17:59,126][__main__][INFO] - [53/81] arch=7->32->16->1 lr=0.0001 batch=128 mom=0.90 -> val_rmsle=0.3691
[2025-11-23 17:18:27,106][__main__][INFO] - [54/81] arch=7->32->16->1 lr=0.0001 batch=128 mom=0.95 -> val_rmsle=0.1261
[2025-11-23 17:19:29,834][__main__][INFO] - [55/81] arch=7->64->32->1 lr=0.001 batch=32 mom=0.50 -> val_rmsle=0.0731
[2025-11-23 17:20:29,999][__main__][INFO] - [56/81] arch=7->64->32->1 lr=0.001 batch=32 mom=0.90 -> val_rmsle=0.0629
[2025-11-23 17:21:27,858][__main__][INFO] - [57/81] arch=7->64->32->1 lr=0.001 batch=32 mom=0.95 -> val_rmsle=0.0557
[2025-11-23 17:22:03,603][__main__][INFO] - [58/81] arch=7->64->32->1 lr=0.001 batch=64 mom=0.50 -> val_rmsle=0.0916
[2025-11-23 17:22:39,220][__main__][INFO] - [59/81] arch=7->64->32->1 lr=0.001 batch=64 mom=0.90 -> val_rmsle=0.0604
[2025-11-23 17:23:14,497][__main__][INFO] - [60/81] arch=7->64->32->1 lr=0.001 batch=64 mom=0.95 -> val_rmsle=0.0580
[2025-11-23 17:23:39,615][__main__][INFO] - [61/81] arch=7->64->32->1 lr=0.001 batch=128 mom=0.50 -> val_rmsle=0.1204
[2025-11-23 17:24:04,071][__main__][INFO] - [62/81] arch=7->64->32->1 lr=0.001 batch=128 mom=0.90 -> val_rmsle=0.0718
[2025-11-23 17:24:30,093][__main__][INFO] - [63/81] arch=7->64->32->1 lr=0.001 batch=128 mom=0.95 -> val_rmsle=0.0626
[2025-11-23 17:25:26,627][__main__][INFO] - [64/81] arch=7->64->32->1 lr=0.01 batch=32 mom=0.50 -> val_rmsle=0.0560
[2025-11-23 17:26:23,618][__main__][INFO] - [65/81] arch=7->64->32->1 lr=0.01 batch=32 mom=0.90 -> val_rmsle=0.0563
[2025-11-23 17:27:20,183][__main__][INFO] - [66/81] arch=7->64->32->1 lr=0.01 batch=32 mom=0.95 -> val_rmsle=0.0579
[2025-11-23 17:27:55,956][__main__][INFO] - [67/81] arch=7->64->32->1 lr=0.01 batch=64 mom=0.50 -> val_rmsle=0.0589
[2025-11-23 17:28:31,562][__main__][INFO] - [68/81] arch=7->64->32->1 lr=0.01 batch=64 mom=0.90 -> val_rmsle=0.0575
[2025-11-23 17:29:06,840][__main__][INFO] - [69/81] arch=7->64->32->1 lr=0.01 batch=64 mom=0.95 -> val_rmsle=0.0579
[2025-11-23 17:29:31,677][__main__][INFO] - [70/81] arch=7->64->32->1 lr=0.01 batch=128 mom=0.50 -> val_rmsle=0.0640
[2025-11-23 17:29:56,158][__main__][INFO] - [71/81] arch=7->64->32->1 lr=0.01 batch=128 mom=0.90 -> val_rmsle=0.0596
[2025-11-23 17:30:20,321][__main__][INFO] - [72/81] arch=7->64->32->1 lr=0.01 batch=128 mom=0.95 -> val_rmsle=0.0589
[2025-11-23 17:31:16,591][__main__][INFO] - [73/81] arch=7->64->32->1 lr=0.0001 batch=32 mom=0.50 -> val_rmsle=0.4708
[2025-11-23 17:32:12,976][__main__][INFO] - [74/81] arch=7->64->32->1 lr=0.0001 batch=32 mom=0.90 -> val_rmsle=0.0915
[2025-11-23 17:33:09,259][__main__][INFO] - [75/81] arch=7->64->32->1 lr=0.0001 batch=32 mom=0.95 -> val_rmsle=0.0748
[2025-11-23 17:33:44,718][__main__][INFO] - [76/81] arch=7->64->32->1 lr=0.0001 batch=64 mom=0.50 -> val_rmsle=0.8008
[2025-11-23 17:34:19,751][__main__][INFO] - [77/81] arch=7->64->32->1 lr=0.0001 batch=64 mom=0.90 -> val_rmsle=0.1206
[2025-11-23 17:34:55,251][__main__][INFO] - [78/81] arch=7->64->32->1 lr=0.0001 batch=64 mom=0.95 -> val_rmsle=0.0885
[2025-11-23 17:35:19,334][__main__][INFO] - [79/81] arch=7->64->32->1 lr=0.0001 batch=128 mom=0.50 -> val_rmsle=0.8406
[2025-11-23 17:35:43,941][__main__][INFO] - [80/81] arch=7->64->32->1 lr=0.0001 batch=128 mom=0.90 -> val_rmsle=0.4023
[2025-11-23 17:36:08,145][__main__][INFO] - [81/81] arch=7->64->32->1 lr=0.0001 batch=128 mom=0.95 -> val_rmsle=0.1251
[2025-11-23 17:36:08,146][__main__][INFO] - Najlepszy wynik bez dropoutu: 0.0557
[2025-11-23 17:36:08,174][__main__][INFO] - Testuję dropout dla najlepszej konfiguracji (arch=7->64->32->1, lr=0.001, batch=32, mom=0.95)
[2025-11-23 17:37:04,559][__main__][INFO] - Dropout 0.00 -> val_rmsle=0.0580
[2025-11-23 17:38:07,845][__main__][INFO] - Dropout 0.10 -> val_rmsle=0.0590
[2025-11-23 17:39:11,515][__main__][INFO] - Dropout 0.20 -> val_rmsle=0.0630
[2025-11-23 17:40:14,955][__main__][INFO] - Dropout 0.30 -> val_rmsle=0.0703
[2025-11-23 17:40:14,956][__main__][INFO] - Najlepszy wynik z dropout: 0.0580 (dropout=0.00)
[2025-11-23 17:45:27,690][__main__][INFO] - Early stopping po 10 epokach bez poprawy (epoka 53, najlepsze 0.0548)
[2025-11-23 17:45:27,763][__main__][INFO] - Zapisano najlepszy model do outputs/2025-11-23/16-41-18/best_model.pth
[2025-11-23 17:45:27,763][__main__][INFO] - Zapisano statystyki normalizacji do outputs/2025-11-23/16-41-18/normalization_stats.pt
[2025-11-23 17:45:27,763][__main__][INFO] - Ostateczny wynik walidacyjny: 0.0548 (epoka 43)
[2025-11-23 17:45:27,763][__main__][INFO] - Historia walidacyjna: [0.07341560195025323, 0.0631324973556534, 0.06938498245104004, 0.05764384143159378, 0.058587395220537235, 0.05691495211079793, 0.05716466620952247, 0.056557778199918494, 0.05697332249649199, 0.058975810333673204, 0.05631939269230406, 0.05622997287733945, 0.056560393739904916, 0.05589531810712641, 0.05589567840817693, 0.05604796268287474, 0.0561553414763228, 0.05619689373143729, 0.0557171978444217, 0.05924338859636273, 0.05664394426703097, 0.05747446442839813, 0.05581147182548463, 0.056003693515854436, 0.055206774559138985, 0.05571433810959014, 0.05513985177308143, 0.05646018165564196, 0.05569885525401084, 0.05545520745996551, 0.05654646608177509, 0.05518706036579029, 0.05748649423865684, 0.05529874929389042, 0.05513777616974157, 0.05501443145354835, 0.055311213769559005, 0.055569743151925886, 0.05514439382533139, 0.05534216373326072, 0.055075377555653046, 0.05508099564227177, 0.05483556010779438, 0.0573692861817294, 0.055402967188850606, 0.05640758921586155, 0.05551254635107777, 0.056066813023678275, 0.054858525608643995, 0.05517702676282731, 0.054988094963095195, 0.05531123682614988, 0.05530233299772894]
